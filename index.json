[
{
	"uri": "/basics/getting-started/",
	"title": "Getting started",
	"tags": [],
	"description": "",
	"content": " Welcome to the intro guide to dkron! This will explain how to setup dkron, how easy is to use it, what problems could it help you to solve, etc.\nIntroduction Dkron nodes can work in two modes, agents or servers.\nA Dkron agent is a cluster member that can handle job executions, run your scripts and return the resulting output to the server.\nA Dkron server is also a cluster member that send job execution queries to agents or other servers, so servers can execute jobs too.\nThe main distinction is that servers order job executions, can be used to schedule jobs, handles data storage and participate on leader election.\nDkron clusters have a leader, the leader is responsible of starting job execution queries in the cluster.\nAny Dkron agent or server acts as a cluster member and it\u0026rsquo;s available to run scheduled jobs.\nYou can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run. This gives an unprecedented level of flexibility in runnig jobs across a cluster of any size and with any combination of machines you need.\nAll the execution responses will be gathered by the scheduler and stored in the database.\nRequirements Dkron relies on the key-value store for data storage, you can run an instance of the distributed store in the same machines as Dkron or connect it to your existing cluster.\nIt can use etcd, Consul or Zookeeper as data stores. To install any of this systems got to their web site:\n etcd Consul ZooKeeper  Installation Recommended method APT repository: deb [trusted=yes] https://apt.fury.io/victorcoder/ /\nUnstable release: sudo apt-get install dkron-unstable Stable release: sudo apt-get install dkron\nOther methods Simply download the packaged archive for your platform from the downloads page, extract the package to a shared location in your drive, like /opt/local and run it from there.\nConfiguration See the configuration section.\nUsage By default Dkron uses the following ports:\n 8946 for communicating between agents 8080 for HTTP for the API and Dashboard 6868 for RPC comunication between agents.  Be sure you have opened this ports (or the ones that you configured) in your firewall or AWS security groups.\nBy default dkron will try to use a local etcd server running in the same machine and in the default port. You can specify the store by setting the backend and backend-machines flag in the config file, env variables or as a command line flag.\nTo start a Dkron server instance just run:\ndkron agent --server  "
},
{
	"uri": "/usage/plugins/processors/",
	"title": "Execution Processors",
	"tags": [],
	"description": "",
	"content": " Execution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do:\n Execution output storage, forwarding or redirection. Notification Monitoring  For example, Processor plugins can be used to redirect the output of a job execution to different targets.\nCurrently Dkron provides you with some built-in plugins but the list keeps growing. Some of the features previously implemented in the application will be progessively moved to plugins.\nBuilt-in processors Dkron provides the following built-in processors:\n not specified - Store the output in the key value store (Slow performance, good for testing, default method) log - Output the execution log to Dkron stdout (Good performance, needs parsing) syslog - Output to the syslog (Good performance, needs parsing) files - Output to multiple files (Good performance, needs parsing)  Dkro Pro provides you with several more processors.\nAll plugins accepts one configuration option: forward Indicated if the plugin must forward the original execution output. This allows for chaining plugins and sending output to different targets at the same time.\nYou can set more than one processor to a job. For example:\n{ \u0026quot;name\u0026quot;: \u0026quot;job_name\u0026quot;, \u0026quot;command\u0026quot;: \u0026quot;/bin/true\u0026quot;, \u0026quot;schedule\u0026quot;: \u0026quot;@every 2m\u0026quot;, \u0026quot;tags\u0026quot;: { \u0026quot;role\u0026quot;: \u0026quot;web\u0026quot; }, \u0026quot;processors\u0026quot;: { \u0026quot;files\u0026quot;: { \u0026quot;forward\u0026quot;: true }, \u0026quot;syslog\u0026quot;: { \u0026quot;forward\u0026quot;: true }, } }  "
},
{
	"uri": "/usage/plugins/executors/",
	"title": "Executors",
	"tags": [],
	"description": "",
	"content": " Executors Executors plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes.\nFor example, the built-in shell executor, will run the indicated command in the target node.\nNew plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\nDkron Pro have commercially supported executors\nAdd this to a job definition to use the shell executor:\n\u0026quot;executor\u0026quot;: \u0026quot;shell\u0026quot;, \u0026quot;executor_config\u0026quot;: { \u0026quot;command\u0026quot;: \u0026quot;echo \\\u0026quot;Hello from dkron\\\u0026quot;\u0026quot; }  Refer to the API documentation for params accepted by the shell executor.\n"
},
{
	"uri": "/usage/plugins/develop/",
	"title": "Developing plugins",
	"tags": [],
	"description": "",
	"content": " Developing a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language.\nNote: A common pitfall is not properly setting up a $GOPATH. This can lead to strange errors. You can read more about this here to familiarize yourself.\nCreate a new Go project somewhere in your $GOPATH. If you\u0026rsquo;re a GitHub user, we recommend creating the project in the directory $GOPATH/src/github.com/USERNAME/dkron-NAME-TYPE, where USERNAME is your GitHub username and NAME is the name of the plugin you\u0026rsquo;re developing. This structure is what Go expects and simplifies things down the road.\nWith the directory made, create a main.go file. This project will be a binary so the package is \u0026ldquo;main\u0026rdquo;:\npackage main import ( \u0026quot;github.com/victorcoder/dkron/plugin\u0026quot; ) func main() { plugin.Serve(\u0026amp;plugin.ServeOpts{ Processor: new(MyPlugin), }) }  And that\u0026rsquo;s basically it! You\u0026rsquo;ll have to change the argument given to plugin.Serve to be your actual plugin, but that is the only change you\u0026rsquo;ll have to make. The argument should be a structure implementing one of the plugin interfaces (depending on what sort of plugin you\u0026rsquo;re creating).\nDkron plugins must follow a very specific naming convention of dkron-TYPE-NAME. For example, dkron-processor-files, which tells Dkron that the plugin is a processor that can be referenced as \u0026ldquo;files\u0026rdquo;.\n"
},
{
	"uri": "/basics/",
	"title": "Basics",
	"tags": [],
	"description": "",
	"content": " Dkron - Distributed, fault tolerant job scheduling system Welcome to the Dkron documentation! This is the reference guide on how to use Dkron. If you want a getting started guide refer to the getting started guide.\nWhat is Dkron Dkron is a distributed system to run scheduled jobs against a server or a group of servers of any size. One of the machines is the leader and the others will be followers. If the leader fails or becomes unreachable, any other one will take over and reschedule all jobs to keep the system healthy.\nIn case the old leader becomes alive again, it\u0026rsquo;ll become a follower.\nDkron is a distributed cron drop-in replacement, easy to setup and fault tolerant with focus in:\n Easy: Easy to use with a great UI Reliable: Completely fault tolerant High scalable: Able to handle high volumes of scheduled jobs and thousands of nodes  Dkron is written in Go and leverage the power of distributed key value stores and Serf for providing fault tolerance, reliability and scalability while keeping simple and easily installable.\nDkron is inspired by the google whitepaper Reliable Cron across the Planet\nDkron runs on Linux, OSX and Windows. It can be used to run scheduled commands on a server cluster using any combination of servers for each job. It has no single points of failure due to the use of the fault tolerant distributed databases and can work at large scale thanks to the efficient and lightweight gossip protocol.\nDkron uses the efficient and lightweight gossip protocol underneath to communicate with nodes. Failure notification and task handling are run efficiently across an entire cluster of any size.\nWeb UI \nDkron design Dkron is designed to solve one problem well, executing commands in given intervals. Following the unix philosophy of doing one thing and doing it well (like the battle-tested cron) but with the given addition of being designed for the cloud era, removing single points of failure in environments where scheduled jobs are needed to be run in multiple servers.\n"
},
{
	"uri": "/usage/",
	"title": "Usage",
	"tags": [],
	"description": "",
	"content": "  API \n  Concurrency  Concurrency Jobs can be configured to allow overlapping executions or forbid them. Concurrency property accepts two option: allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule. Example: { \u0026quot;name\u0026quot;: \u0026quot;job1\u0026quot;, \u0026quot;schedule\u0026quot;: \u0026quot;@every 10s\u0026quot;, \u0026quot;executor\u0026quot;: \u0026quot;shell\u0026quot;, \u0026quot;executor_config\u0026quot;: { \u0026quot;command\u0026quot;: \u0026quot;echo \\\u0026quot;Hello from parent\\\u0026quot;\u0026quot; }, \u0026quot;concurrency\u0026quot;: \u0026quot;forbid\u0026quot; }   Cron spec CRON Expression Format A cron expression represents a set of times, using 6 space-separated fields. Field name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ?\n  Job chaining \n  Job retries \n  Metrics \n  Plugins \n  Execution Processors Execution Processors Processor plugins are called when an execution response has been received. They are passed the resulting execution data and configuration parameters, this plugins can perform a variety of operations with the execution and it\u0026rsquo;s very flexible and per Job, examples of operations this plugins can do: Execution output storage, forwarding or redirection. Notification Monitoring For example, Processor plugins can be used to redirect the output of a job execution to different targets.\n  Executors Executors Executors plugins are the main mechanism of execution in Dkron. They implement different \u0026ldquo;types\u0026rdquo; of jobs in the sense that they can perform the most diverse actions on the target nodes. For example, the built-in shell executor, will run the indicated command in the target node. New plugins will be added, or you can create new ones, to perform different tasks, as HTTP requests, Docker runs, anything that you can imagine.\n  Developing plugins Developing a Plugin Advanced topic! Plugin development is a highly advanced topic, and is not required knowledge for day-to-day usage. If you don\u0026rsquo;t plan on writing any plugins, we recommend not reading the following section of the documentation. Developing a plugin is simple. The only knowledge necessary to write a plugin is basic command-line skills and basic knowledge of the Go programming language. Note: A common pitfall is not properly setting up a $GOPATH.\n  Target nodes spec \n  Use with AWS ECS \n  "
},
{
	"uri": "/_header/",
	"title": "header",
	"tags": [],
	"description": "",
	"content": "Dkron  "
},
{
	"uri": "/_footer/",
	"title": "",
	"tags": [],
	"description": "",
	"content": "Distributed Works Â© 2015 Victor Castell - victor@distrib.works\n"
},
{
	"uri": "/usage/api/",
	"title": "API",
	"tags": [],
	"description": "",
	"content": " Dkron REST API \nOverview You can communicate with Dkron using a RESTful JSON API over HTTP. Dkron nodes usually listen on port 8080 for API requests. All examples in this section assume that you\u0026rsquo;ve found a running leader at localhost:8080.\nDkron implements a RESTful JSON API over HTTP to communicate with software clients. Dkron listens in port 8080 by default. All examples in this section assume that you\u0026rsquo;re using the default port.\nDefault API responses are unformatted JSON add the pretty=true param to format the response.\nVersion information Version : 0.10.0\nURI scheme Host : localhost:8080\nBasePath : /v1\nSchemes : HTTP\nConsumes  application/json  Produces  application/json  \nPaths \nGET / Description Gets Status object.\nResponses    HTTP Code Description Schema     200 Successful response status    Tags  default  Example HTTP request Request path /  Example HTTP response Response 200 json : \u0026quot;{ }\u0026quot;  \nGET /jobs Description List jobs.\nResponses    HTTP Code Description Schema     200 Successful response \u0026lt; job \u0026gt; array    Tags  jobs  Example HTTP request Request path /jobs  Example HTTP response Response 200 json : \u0026quot;array\u0026quot;  \nPOST /jobs Description Create or updates a new job.\nParameters    Type Name Description Schema     Body body required Updated job object job    Responses    HTTP Code Description Schema     201 Successful response job    Tags  jobs  Example HTTP request Request path /jobs  Request body json : { \u0026quot;name\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;schedule\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;timezone\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner_email\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;success_count\u0026quot; : 0, \u0026quot;error_count\u0026quot; : 0, \u0026quot;last_success\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;last_error\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;disabled\u0026quot; : true, \u0026quot;tags\u0026quot; : { \u0026quot;string\u0026quot; : \u0026quot;string\u0026quot; }, \u0026quot;retries\u0026quot; : 2, \u0026quot;parent_job\u0026quot; : \u0026quot;parent_job\u0026quot;, \u0026quot;dependent_jobs\u0026quot; : [ \u0026quot;string\u0026quot; ], \u0026quot;processors\u0026quot; : { }, \u0026quot;concurrency\u0026quot; : \u0026quot;allow\u0026quot;, \u0026quot;executor\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;executor_config\u0026quot; : { } }  Example HTTP response Response 201 json : { \u0026quot;name\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;schedule\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;timezone\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner_email\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;success_count\u0026quot; : 0, \u0026quot;error_count\u0026quot; : 0, \u0026quot;last_success\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;last_error\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;disabled\u0026quot; : true, \u0026quot;tags\u0026quot; : { \u0026quot;string\u0026quot; : \u0026quot;string\u0026quot; }, \u0026quot;retries\u0026quot; : 2, \u0026quot;parent_job\u0026quot; : \u0026quot;parent_job\u0026quot;, \u0026quot;dependent_jobs\u0026quot; : [ \u0026quot;string\u0026quot; ], \u0026quot;processors\u0026quot; : { }, \u0026quot;concurrency\u0026quot; : \u0026quot;allow\u0026quot;, \u0026quot;executor\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;executor_config\u0026quot; : { } }  \nGET /jobs/{job_name} Description Show a job.\nParameters    Type Name Description Schema     Path job_name required The job that needs to be fetched. string    Responses    HTTP Code Description Schema     200 Successful response job    Tags  jobs  Example HTTP request Request path /jobs/string  Example HTTP response Response 200 json : { \u0026quot;name\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;schedule\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;timezone\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner_email\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;success_count\u0026quot; : 0, \u0026quot;error_count\u0026quot; : 0, \u0026quot;last_success\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;last_error\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;disabled\u0026quot; : true, \u0026quot;tags\u0026quot; : { \u0026quot;string\u0026quot; : \u0026quot;string\u0026quot; }, \u0026quot;retries\u0026quot; : 2, \u0026quot;parent_job\u0026quot; : \u0026quot;parent_job\u0026quot;, \u0026quot;dependent_jobs\u0026quot; : [ \u0026quot;string\u0026quot; ], \u0026quot;processors\u0026quot; : { }, \u0026quot;concurrency\u0026quot; : \u0026quot;allow\u0026quot;, \u0026quot;executor\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;executor_config\u0026quot; : { } }  \nPOST /jobs/{job_name} Description Executes a job.\nParameters    Type Name Description Schema     Path job_name required The job that needs to be run. string    Responses    HTTP Code Description Schema     202 Successful response job    Tags  jobs  Example HTTP request Request path /jobs/string  Example HTTP response Response 202 json : { \u0026quot;name\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;schedule\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;timezone\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner_email\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;success_count\u0026quot; : 0, \u0026quot;error_count\u0026quot; : 0, \u0026quot;last_success\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;last_error\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;disabled\u0026quot; : true, \u0026quot;tags\u0026quot; : { \u0026quot;string\u0026quot; : \u0026quot;string\u0026quot; }, \u0026quot;retries\u0026quot; : 2, \u0026quot;parent_job\u0026quot; : \u0026quot;parent_job\u0026quot;, \u0026quot;dependent_jobs\u0026quot; : [ \u0026quot;string\u0026quot; ], \u0026quot;processors\u0026quot; : { }, \u0026quot;concurrency\u0026quot; : \u0026quot;allow\u0026quot;, \u0026quot;executor\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;executor_config\u0026quot; : { } }  \nDELETE /jobs/{job_name} Description Delete a job.\nParameters    Type Name Description Schema     Path job_name required The job that needs to be deleted. string    Responses    HTTP Code Description Schema     200 Successful response job    Tags  jobs  Example HTTP request Request path /jobs/string  Example HTTP response Response 200 json : { \u0026quot;name\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;schedule\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;timezone\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;owner_email\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;success_count\u0026quot; : 0, \u0026quot;error_count\u0026quot; : 0, \u0026quot;last_success\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;last_error\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;disabled\u0026quot; : true, \u0026quot;tags\u0026quot; : { \u0026quot;string\u0026quot; : \u0026quot;string\u0026quot; }, \u0026quot;retries\u0026quot; : 2, \u0026quot;parent_job\u0026quot; : \u0026quot;parent_job\u0026quot;, \u0026quot;dependent_jobs\u0026quot; : [ \u0026quot;string\u0026quot; ], \u0026quot;processors\u0026quot; : { }, \u0026quot;concurrency\u0026quot; : \u0026quot;allow\u0026quot;, \u0026quot;executor\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;executor_config\u0026quot; : { } }  \nGET /jobs/{job_name}/executions Description List executions.\nParameters    Type Name Description Schema     Path job_name required The job that owns the executions to be fetched. string    Responses    HTTP Code Description Schema     200 Successful response \u0026lt; execution \u0026gt; array    Tags  executions  Example HTTP request Request path /jobs/string/executions  Example HTTP response Response 200 json : \u0026quot;array\u0026quot;  \nGET /leader Description List leader of cluster.\nResponses    HTTP Code Description Schema     200 Successful response member    Tags  default  Example HTTP request Request path /leader  Example HTTP response Response 200 json : { \u0026quot;Name\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;Addr\u0026quot; : \u0026quot;string\u0026quot;, \u0026quot;Port\u0026quot; : 0, \u0026quot;Tags\u0026quot; : { \u0026quot;string\u0026quot; : \u0026quot;string\u0026quot; }, \u0026quot;Status\u0026quot; : 0, \u0026quot;ProtocolMin\u0026quot; : 0, \u0026quot;ProtocolMax\u0026quot; : 0, \u0026quot;ProtocolCur\u0026quot; : 0, \u0026quot;DelegateMin\u0026quot; : 0, \u0026quot;DelegateMax\u0026quot; : 0, \u0026quot;DelegateCur\u0026quot; : 0 }  \nGET /leave Description Force the node to leave the cluster.\nResponses    HTTP Code Description Schema     200 Successful response \u0026lt; member \u0026gt; array    Tags  default  Example HTTP request Request path /leave  Example HTTP response Response 200 json : \u0026quot;array\u0026quot;  \nGET /members Description List members.\nResponses    HTTP Code Description Schema     200 Successful response \u0026lt; member \u0026gt; array    Tags  members  Example HTTP request Request path /members  Example HTTP response Response 200 json : \u0026quot;array\u0026quot;  \nDefinitions \nstatus Status represents details about the node.\nType : object\n\njob A Job represents a scheduled task to execute.\n   Name Description Schema     name required Name for the job. Example : \u0026quot;string\u0026quot; string   schedule required Cron expression for the job. Example : \u0026quot;string\u0026quot; string   timezone optional Timezone where the job will be executed. By default and when field is set to empty string, the job will run in local time. Example : \u0026quot;string\u0026quot; string   owner optional Owner of the job Example : \u0026quot;string\u0026quot; string   owner_email optional Email of the owner Example : \u0026quot;string\u0026quot; string   success_count optional read-only Number of successful executions Example : 0 integer   error_count optional read-only Number of failed executions Example : 0 integer   last_success optional read-only Last time this job executed successfully Example : \u0026quot;string\u0026quot; string(date-time)   last_error optional read-only Last time this job failed Example : \u0026quot;string\u0026quot; string(date-time)   disabled optional Disabled state of the job Example : true boolean   tags optional Target nodes tags of this job Example : {\u0026lt;br\u0026gt; \u0026quot;string\u0026quot; : \u0026quot;string\u0026quot;\u0026lt;br\u0026gt;} \u0026lt; string, string \u0026gt; map   retries optional Number of times to retry a failed job execution Example : 2 integer   parent_job optional The name/id of the job that will trigger the execution of this job Example : \u0026quot;parent_job\u0026quot; string   dependent_jobs optional Array containing the jobs that depends on this one Example : [ \u0026quot;string\u0026quot; ] \u0026lt; string \u0026gt; array   processors optional Example : \u0026quot;[processors](#processors)\u0026quot; processors   concurrency optional Concurrency policy for the job allow/forbid Example : \u0026quot;allow\u0026quot; string   executor optional Executor plugin used to run the job Example : \u0026quot;string\u0026quot; string   executor_config optional Example : \u0026quot;[executor_config](#executor_config)\u0026quot; executor_config    \nmember A member represents a cluster member node.\n   Name Description Schema     Name optional Node name Example : \u0026quot;string\u0026quot; string   Addr optional IP Address Example : \u0026quot;string\u0026quot; string   Port optional Port number Example : 0 integer   Tags optional Tags asociated with this node Example : {\u0026lt;br\u0026gt; \u0026quot;string\u0026quot; : \u0026quot;string\u0026quot;\u0026lt;br\u0026gt;} \u0026lt; string, string \u0026gt; map   Status optional The serf status of the node see: https://godoc.org/github.com/hashicorp/serf/serf#MemberStatus Example : 0 integer   ProtocolMin optional Serf protocol minimum version this node can understand or speak Example : 0 integer   ProtocolMax optional Serf protocol maximum version this node can understand or speak Example : 0 integer   ProtocolCur optional Serf protocol current version this node can understand or speak Example : 0 integer   DelegateMin optional Serf delegate protocol minimum version this node can understand or speak Example : 0 integer   DelegateMax optional Serf delegate protocol maximum version this node can understand or speak Example : 0 integer   DelegateCur optional Serf delegate protocol current version this node can understand or speak Example : 0 integer    \nexecution An execution represents a timed job run.\n   Name Description Schema     job_name optional job name Example : \u0026quot;string\u0026quot; string   started_at optional start time of the execution Example : \u0026quot;string\u0026quot; string(date-time)   finished_at optional when the execution finished running Example : \u0026quot;string\u0026quot; string(date-time)   success optional the execution run successfuly Example : true boolean   output optional partial output of the command execution Example : \u0026quot;string\u0026quot; string   node_name optional name of the node that executed the command Example : \u0026quot;string\u0026quot; string    \nprocessors Processor plugins used to process executions results of this job\nType : \u0026lt; string, \u0026lt; string, string \u0026gt; map \u0026gt; map\n\nprocessor_files Files processor save execution output to disk files.\n   Name Description Schema     forward optional Forward the output to the next processor Example : true boolean   log_dir optional Example : \u0026quot;string\u0026quot; string    \nprocessor_log Log processor saves executions output to the dkron log\n   Name Description Schema     forward optional Forward the output to the next processor Example : true boolean    \nprocessor_syslog Syslog processor route execution output to syslog\n   Name Description Schema     forward optional Forward the output to the next processor Example : true boolean    \nexecutor_config Executor plugin parameters\nType : \u0026lt; string, string \u0026gt; map\n\nexecutor_shell Shell executor runs a command in shell\n   Name Description Schema     command optional Command to run Example : \u0026quot;string\u0026quot; string   env optional Comma separated environment variables pair Example : \u0026quot;FOO=bar\u0026quot; string   shell optional Example : true boolean    "
},
{
	"uri": "/pro/auth/",
	"title": "Authorization",
	"tags": [],
	"description": "",
	"content": "Dkron Pro has the ability to be configured to use HTTP basic auth.\nSet this parameters in your dkron config file:\nusername: foo password: bar  This will enable auth on the WebUI and for the API.\n"
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/commercial-faq/",
	"title": "Commercial FAQ",
	"tags": [],
	"description": "",
	"content": " What is Dkron Pro? Dkron Pro is a flavor of Dkron which add more functionality and provide additional support options for customers.\nIs there a trial version? There\u0026rsquo;s no free trial but we do offer a 14 day period with full refund if it does not work for you.\nCan I get a discount? I\u0026rsquo;m sure you\u0026rsquo;re very nice but no. Everyone pays the same price.\nWhat is the license? See COMM-LICENSE.\nHow does Pro licensing work? Every organization running Dkron Pro on its own servers must have a license. There\u0026rsquo;s no limit to the number of servers or environments used by that organization.\nWhat happens if my subscription lapses? You must have an active subscription to run Dkron Pro. After a one week grace period, you\u0026rsquo;ll lose access to the package repository and priority support. You won\u0026rsquo;t get any more updates or bug fixes and \u0026lsquo;apt-get install dkron-pro\u0026rsquo; won\u0026rsquo;t work anymore.\nCan I distribute Dkron Pro to my customers? This is a common requirement for \u0026ldquo;on-site installs\u0026rdquo; or \u0026ldquo;appliances\u0026rdquo; sold to large corporations.\nThe standard license is only appropriate for SaaS usage as it does not allow distribution. Dkron Pro have an Appliance license option which does allow you to distribute them. The Appliance license is $3,950/yr for Pro. It allows you to distribute the Pro binaries as part of your application and each of your customers to run Dkron Pro as part of your application only. Email support\u0026#64;distrib.works to purchase.\nCan you transfer a license? Licenses are not transferrable to another company. We will transfer the license from a user-specific email to a group email address (e.g. john_smith@example.com -\u0026gt; tech@example.com) but only for the same domain. It is strongly recommended that you buy the license using a group email address so the license is not attached to any one employee\u0026rsquo;s email address.\nWhat does the license require me to do? Your purchase gets you unique access credentials for downloading the Pro packages. The license agreement requires you to keep these access credentials private. If we find your access credentials are ever publicized:\n We\u0026rsquo;ll send you a warning email with details. You need to remove the content and send a new email address so we can generate new credentials for you. The old credentials will stop working immediately so you\u0026rsquo;ll need to update your apps. If your credentials are publicized a second time, we reserve the right to permanently remove access (but won\u0026rsquo;t unless it\u0026rsquo;s really egregious - sloppy contractors happen).  Can I get a refund? Yes, up to two weeks after purchase. Let us know the reason and maybe we can help but either way it\u0026rsquo;s not a problem. Email support\u0026#64;distrib.works.\nHow do I update my credit card info? If you purchased Dkron Pro (settings) with a credit card, log into Gumroad with your email address, click the Settings, enter your card info and hit Save. Follow instructions in Gumroad docs https://help.gumroad.com/how-do-i-update-my-credit-card-information I can\u0026rsquo;t provide support for the Gumroad website and don\u0026rsquo;t have the ability to edit customer info - if you can\u0026rsquo;t log in or change your credit card, you can always let your current subscription expire and purchase a new subscription.\nCan I request a change to the license terms? Dkron Pro is sold as is, no change to terms.\nCan I pay via invoice and purchase order? Dkron Pro is credit card only, no exceptions.\nContact Info Distributed Works\nAll billing/support inquiries: support@distrib.works\nPhone: not available\n"
},
{
	"uri": "/commercial-support/",
	"title": "Commercial Support",
	"tags": [],
	"description": "",
	"content": " Dkron offers only community support. Dkro Pro offers priority support via email.\nPriority Support Covers 1 incident per quarter, with a max response time of 2 working days. Scope is limited to Dkron and Dkron Pro features and APIs, not the application or infrastructure. For support, email support AT distrib.works. Please email using the same domain as the original license email or explain your connection to the licensed company.\n"
},
{
	"uri": "/usage/concurrency/",
	"title": "Concurrency",
	"tags": [],
	"description": "",
	"content": " Concurrency Jobs can be configured to allow overlapping executions or forbid them.\nConcurrency property accepts two option:\n allow (default): Allow concurrent job executions. forbid: If the job is already running don\u0026rsquo;t send the execution, it will skip the executions until the next schedule.  Example:\n{ \u0026quot;name\u0026quot;: \u0026quot;job1\u0026quot;, \u0026quot;schedule\u0026quot;: \u0026quot;@every 10s\u0026quot;, \u0026quot;executor\u0026quot;: \u0026quot;shell\u0026quot;, \u0026quot;executor_config\u0026quot;: { \u0026quot;command\u0026quot;: \u0026quot;echo \\\u0026quot;Hello from parent\\\u0026quot;\u0026quot; }, \u0026quot;concurrency\u0026quot;: \u0026quot;forbid\u0026quot; }  "
},
{
	"uri": "/basics/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": " Settings for dkron can be specified in three ways: Using a config/dkron.json config file, using env variables starting with DKRON_ or using command line arguments.\nCommand line options  --node-name - Name of the node, must be unique in the cluster. By default this is the hostname of the machine.\n --bind-addr - The address that dkron will bind to for communication with other dkron nodes. By default this is \u0026ldquo;0.0.0.0:8946\u0026rdquo;. dkron nodes may have different ports. If a join is specified without a port, we default to locally configured port. dkron uses both TCP and UDP and use the same port for both, so if you have any firewalls be sure to allow both protocols. If this configuration value is changed and no port is specified, the default of \u0026ldquo;8946\u0026rdquo; will be used.\n --join - Address of another agent to join upon starting up. This can be specified multiple times to specify multiple agents to join. If Dkron is unable to join with any of the specified addresses, agent startup will fail. By default, the agent won\u0026rsquo;t join any nodes when it starts up.\n --advertise-addr - The advertise flag is used to change the address that we advertise to other nodes in the cluster. By default, the bind address is advertised. However, in some cases (specifically NAT traversal), there may be a routable address that cannot be bound to. This flag enables gossiping a different address to support this. If this address is not routable, the node will be in a constant flapping state, as other nodes will treat the non-routability as a failure.\n --http-addr - The address where the web UI will be binded. By default :8080\n --backend - Backend storage to use, etcd, consul, zk (zookeeper) or redis. The default is etcd.\n --backend-machine - Backend storage servers addresses to connect to. This flag can be specified multiple times. By default 127.0.0.1:2379\n --tag - The tag flag is used to associate a new key/value pair with the agent. The tags are gossiped and can be used to provide additional information such as roles, ports, and configuration values to other nodes. Multiple tags can be specified per agent. There is a byte size limit for the maximum number of tags, but in practice dozens of tags may be used. Tags can be changed during a config reload.\n --server - If this agent is a dkron server, just need to be present. Absent by default.\n --keyspace - Keyspace to use for the store. Allows to run different instances using the same storage cluster. dkron by default.\n --encrypt - Key for encrypting network traffic. Must be a base64-encoded 16-byte key.\n --mail-host - Mail server host address to use for notifications.\n --mail-port - Mail server port.\n --mail-username - Mail server username used for authentication.\n --mail-password - Mail server password to use.\n --mail-from - From email address to use.\n --webhook-url - Webhook url to call for notifications.\n --webhook-payload - Body of the POST request to send on webhook call.\n --webhook-header - Headers to use when calling the webhook URL. Can be specified multiple times.\n --log-level - Set the log level (debug, info, warn, error, fatal, panic). Defaults to \u0026ldquo;info\u0026rdquo;\n --rpc-port - The port that Dkron will use to bind for the agent\u0026rsquo;s RPC server, defaults to 6868. The RPC address will be the bind address.\n  Config file example # Dkron example configuration file # backend: etcd # backend_machine: 127.0.0.1:2379 # server: false # log_level: debug # tags: # role: web # datacenter: east # keyspace: dkron # encrypt: a-valid-key-generated-with-dkron-keygen # join: # - 10.0.0.1 # - 10.0.0.2 # - 10.0.0.3 # webhook_url: https://hooks.slack.com/services/XXXXXX/XXXXXXX/XXXXXXXXXXXXXXXXXXXX # webhook_payload: \u0026quot;payload={\\\u0026quot;text\\\u0026quot;: \\\u0026quot;{{.Report}}\\\u0026quot;, \\\u0026quot;channel\\\u0026quot;: \\\u0026quot;#foo\\\u0026quot;}\u0026quot; # webhook_headers: Content-Type:application/x-www-form-urlencoded # mail_host: email-smtp.eu-west-1.amazonaws.com # mail_port: 25 # mail_username\u0026quot;: mailuser # mail_password\u0026quot;: mailpassword # mail_from\u0026quot;: cron@example.com # mail_subject_prefix: [Dkron]  "
},
{
	"uri": "/usage/cron-spec/",
	"title": "Cron spec",
	"tags": [],
	"description": "",
	"content": " CRON Expression Format A cron expression represents a set of times, using 6 space-separated fields.\nField name | Mandatory? | Allowed values | Allowed special characters ---------- | ---------- | -------------- | -------------------------- Seconds | Yes | 0-59 | * / , - Minutes | Yes | 0-59 | * / , - Hours | Yes | 0-23 | * / , - Day of month | Yes | 1-31 | * / , - ? Month | Yes | 1-12 or JAN-DEC | * / , - Day of week | Yes | 0-6 or SUN-SAT | * / , - ?  Note: Month and Day-of-week field values are case insensitive. \u0026ldquo;SUN\u0026rdquo;, \u0026ldquo;Sun\u0026rdquo;, and \u0026ldquo;sun\u0026rdquo; are equally accepted.\nSpecial Characters\nAsterisk ( * )\nThe asterisk indicates that the cron expression will match for all values of the field; e.g., using an asterisk in the 5th field (month) would indicate every month.\nSlash ( / )\nSlashes are used to describe increments of ranges. For example 3-59\u0026frasl;15 in the 1st field (minutes) would indicate the 3rd minute of the hour and every 15 minutes thereafter. The form \u0026ldquo;*\\/\u0026hellip;\u0026rdquo; is equivalent to the form \u0026ldquo;first-last/\u0026hellip;\u0026rdquo;, that is, an increment over the largest possible range of the field. The form \u0026ldquo;N/\u0026hellip;\u0026rdquo; is accepted as meaning \u0026ldquo;N-MAX/\u0026hellip;\u0026rdquo;, that is, starting at N, use the increment until the end of that specific range. It does not wrap around.\nComma ( , )\nCommas are used to separate items of a list. For example, using \u0026ldquo;MON,WED,FRI\u0026rdquo; in the 5th field (day of week) would mean Mondays, Wednesdays and Fridays.\nHyphen ( - )\nHyphens are used to define ranges. For example, 9-17 would indicate every hour between 9am and 5pm inclusive.\nQuestion mark ( ? )\nQuestion mark may be used instead of \u0026lsquo;*\u0026rsquo; for leaving either day-of-month or day-of-week blank.\nPredefined schedules You may use one of several pre-defined schedules in place of a cron expression.\nEntry | Description | Equivalent To ----- | ----------- | ------------- @yearly (or @annually) | Run once a year, midnight, Jan. 1st | 0 0 0 1 1 * @monthly | Run once a month, midnight, first of month | 0 0 0 1 * * @weekly | Run once a week, midnight on Sunday | 0 0 0 * * 0 @daily (or @midnight) | Run once a day, midnight | 0 0 0 * * * @hourly | Run once an hour, beginning of hour | 0 0 * * * * @minutely | Run once a minute, beginning of minute | 0 * * * * *  Intervals You may also schedule a job to execute at fixed intervals. This is supported by formatting the cron spec like this:\n@every \u0026lt;duration\u0026gt;  where \u0026ldquo;duration\u0026rdquo; is a string accepted by time.ParseDuration (http://golang.org/pkg/time/#ParseDuration).\nFor example, \u0026ldquo;@every 1h30m10s\u0026rdquo; would indicate a schedule that activates every 1 hour, 30 minutes, 10 seconds.\nNote: The interval does not take the job runtime into account. For example, if a job takes 3 minutes to run, and it is scheduled to run every 5 minutes, it will have only 2 minutes of idle time between each run.\nFixed times You may also want to schedule a job to be executed once. This is supported by formatting the cron spec like this:\n@at \u0026lt;datetime\u0026gt;  Where \u0026ldquo;datetime\u0026rdquo; is a string accepted by time.Parse in RFC3339 format (https://golang.org/pkg/time/#Parse).\nFor example, \u0026ldquo;@at 2018-01-02T15:04:00Z\u0026rdquo; would run the job on the specified date and time assuming UTC timezone.\nTime zones Dkron is able to schedule jobs in time zones, if you specify the timezone parameter in a job definition.\nIf the time zone is not specified, the following rules apply:\nAll interpretation and scheduling is done in the machine\u0026rsquo;s local time zone (as provided by the Go time package (http://www.golang.org/pkg/time).\nBe aware that jobs scheduled during daylight-savings leap-ahead transitions will not be run!\nIf you specify timezone the job will be schduled taking into account daylight-savings and leap-ahead transitions, running the job in the actual time in the specified time zone.\n"
},
{
	"uri": "/",
	"title": "Dkron - Distributed job scheduling system",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": "  Authorization Dkron Pro has the ability to be configured to use HTTP basic auth. Set this parameters in your dkron config file: username: foo password: bar This will enable auth on the WebUI and for the API.\n  Docker executor  Docker executor can run docker jobs Configuration To run a docker job create a job config with the following executor: Example: \u0026quot;executor\u0026quot;: \u0026quot;docker\u0026quot;, \u0026quot;executor_config\u0026quot;: { \u0026quot;image\u0026quot;: \u0026quot;alpine\u0026quot;, //docker image to use \u0026quot;volumes\u0026quot;: \u0026quot;/logs:/var/log/\u0026quot;, //comma separated list of volume mappings \u0026quot;command\u0026quot;: \u0026quot;echo \\\u0026quot;Hello from dkron\\\u0026quot;\u0026quot;, //command to pass to run on container \u0026quot;env\u0026quot;: \u0026quot;ENVIRONMENT=variable\u0026quot; //environment variables to pass to the container }   Elasticsearch processor  The Elasticsearch processor can fordward execution logs to an ES cluster. Configuration \u0026quot;processors\u0026quot;: { \u0026quot;elasticsearch\u0026quot;: { \u0026quot;url\u0026quot;: \u0026quot;http://localhost:9200\u0026quot;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026quot;index\u0026quot;: \u0026quot;dkron_logs\u0026quot;, //desired index name (default: dkron_logs) \u0026quot;forward\u0026quot;: \u0026quot;false\u0026quot; //forward logs to the next processor (default: false) } }   Email processor If you need special email notification rules for a job, use the Email processor. Example: \u0026quot;processors\u0026quot;: { \u0026quot;email\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;mail.google.com\u0026quot;, \u0026quot;username\u0026quot;: \u0026quot;foo\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;bar\u0026quot;, \u0026quot;emails\u0026quot;: \u0026quot;team@example.com\u0026quot;, \u0026quot;from\u0026quot;: \u0026quot;cron@example.com\u0026quot;, \u0026quot;subject_prefix\u0026quot;: \u0026quot;[Dkron]\u0026quot; } }   Embedded storage Dkron Pro has an embedded distributed KV store engine based on etcd. This works out of the box on each node dkron server is started. This ensures a dead easy install and setup, basically run dkron and you will have a full working node and at the same time provides you with a fully tested well supported store for its use with dkron. Configuration The embedded etcd instance configuration can be tunned using the standard etcd config yaml file located in config/etcd.\n  Encryption SSL encryption is used for communicating dkron pro and the embedded store, and between storage nodes itself. Also client auth is enabled, so only dkron pro clients can talk to the embedded store. This means that no other software running on your local network will be able to talk to dkron\u0026rsquo;s etcd server. This ensures that no unexpected usage of the Dkron\u0026rsquo;s store will happen, unless it is another Dkron pro instance.\n  "
},
{
	"uri": "/products/pro/",
	"title": "Dkron Pro",
	"tags": [],
	"description": "",
	"content": "Dkron Pro Improved security, features and reliability for your scheduled jobs      Get additional fetures and commercial support from the creator of Dkron\n Key features Embedded storage  When it comes to choose a storage you could be making a wrong decission. Easy of use comes from having a well tested and supported storage.\nThe embedded etcd storage is tuned for use with dkron out of the box.\nSecurity  Pro has enhanced security using industry standard SSL encryption for communication between the embedded storage engine and the application.\nYou can also enable basic authentication to restrict access to the WebUI and the API.\nPro plugins  Do you need to store job output in Elasticsearch? Do you need to run docker based jobs?\nDkron Pro adds some commercially supported plugins ready to cover your needs.\n    Product details FEATURES  Dkron Pro contains the following functionality:  Enable more complex job workflows with Batches and Callbacks Better server reliability in the face of Ruby VM crashes Better client reliability in the face of Redis networking problems Pause queues (e.g. only process a queue during business hours) Expire unprocessed jobs after a deadline Send job processing metrics to Statsd High performance API extensions using Redis's Lua support Search for jobs in the Web UI  DOCUMENTATION Detailed documentation about configuring and using each feature can be found in the Dkron docs site. Read the Commercial FAQ for further detail.\nSUPPORT Your subscription gives you priority email support for any issues which might arise.\nSales of Dkron Pro also benefit the community by ensuring that Dkron itself will remain well supported for the foreseeable future.\nINSTALLATION When you buy Dkron Pro, a custom URL associated with your email address will be sent to you. You use this URL to install the package corresponding to your architecture. You configure and use Dkron Pro exactly like you would Dkron.\nPro tip: use a mailing list for your email when purchasing to ensure you get critical email updates, even if employees leave the company.\nUPGRADES Dkron Pro will receive bug fixes and new functionality over time. All upgrades will be free to subscribers with a simple package upgrade. See the changelog for more detail.\nLICENSING Dkron is available under the terms of the GNU LGPLv3 license.\nIn addition to its useful functionality, buying Dkron Pro grants your organization a Dkron commercial license instead of the GNU LGPL, avoiding any legal issues your lawyers might raise. Please see the Commercial FAQ for further detail on licensing including options for distributing Dkron Pro with your own products.\n   "
},
{
	"uri": "/dkron_vs_other_software/",
	"title": "Dkron vs. Other Software",
	"tags": [],
	"description": "",
	"content": " Dkron vs. Chronos Airbnb\u0026rsquo;s Chronos is a job scheduler that is similar to dkron, it\u0026rsquo;s distributed and fault tolerant thanks to the use of Zookeeper and Apache Mesos.\nIf you don\u0026rsquo;t have/want to run a Mesos cluster and deal with the not easy configuration and maintenance of Zookeeper and you want something lighter, Dkron could help you.\nDkron vs. Rundeck Rundeck is a popular and mature platform to automate operations and schedule jobs.\nIt has cool features:\n Agentless Permissions and auditing  It\u0026rsquo;s written in Java and it\u0026rsquo;s not trivial to setup right.\nIt uses a central database to store job execution results and configuration data, that makes it vulnerable to failures, and you need to care yourself of providing an HA environement for the database, and that\u0026rsquo;s not an easy task to do with the Rundeck\u0026rsquo;s supported databases.\nDkron lacks some of it\u0026rsquo;s features but it\u0026rsquo;s lightweight and fault-tolerant out-of-the-box.\n"
},
{
	"uri": "/pro/docker/",
	"title": "Docker executor",
	"tags": [],
	"description": "",
	"content": " Docker executor can run docker jobs\nConfiguration To run a docker job create a job config with the following executor:\nExample:\n\u0026quot;executor\u0026quot;: \u0026quot;docker\u0026quot;, \u0026quot;executor_config\u0026quot;: { \u0026quot;image\u0026quot;: \u0026quot;alpine\u0026quot;, //docker image to use \u0026quot;volumes\u0026quot;: \u0026quot;/logs:/var/log/\u0026quot;, //comma separated list of volume mappings \u0026quot;command\u0026quot;: \u0026quot;echo \\\u0026quot;Hello from dkron\\\u0026quot;\u0026quot;, //command to pass to run on container \u0026quot;env\u0026quot;: \u0026quot;ENVIRONMENT=variable\u0026quot; //environment variables to pass to the container }  "
},
{
	"uri": "/pro/elasticsearch/",
	"title": "Elasticsearch processor",
	"tags": [],
	"description": "",
	"content": " The Elasticsearch processor can fordward execution logs to an ES cluster.\nConfiguration \u0026quot;processors\u0026quot;: { \u0026quot;elasticsearch\u0026quot;: { \u0026quot;url\u0026quot;: \u0026quot;http://localhost:9200\u0026quot;, //comma separated list of Elasticsearch hosts urls (default: http://localhost:9200) \u0026quot;index\u0026quot;: \u0026quot;dkron_logs\u0026quot;, //desired index name (default: dkron_logs) \u0026quot;forward\u0026quot;: \u0026quot;false\u0026quot; //forward logs to the next processor (default: false) } }  "
},
{
	"uri": "/pro/email/",
	"title": "Email processor",
	"tags": [],
	"description": "",
	"content": "If you need special email notification rules for a job, use the Email processor.\nExample:\n\u0026quot;processors\u0026quot;: { \u0026quot;email\u0026quot;: { \u0026quot;host\u0026quot;: \u0026quot;mail.google.com\u0026quot;, \u0026quot;username\u0026quot;: \u0026quot;foo\u0026quot;, \u0026quot;password\u0026quot;: \u0026quot;bar\u0026quot;, \u0026quot;emails\u0026quot;: \u0026quot;team@example.com\u0026quot;, \u0026quot;from\u0026quot;: \u0026quot;cron@example.com\u0026quot;, \u0026quot;subject_prefix\u0026quot;: \u0026quot;[Dkron]\u0026quot; } }  "
},
{
	"uri": "/pro/storage/",
	"title": "Embedded storage",
	"tags": [],
	"description": "",
	"content": " Dkron Pro has an embedded distributed KV store engine based on etcd. This works out of the box on each node dkron server is started.\nThis ensures a dead easy install and setup, basically run dkron and you will have a full working node and at the same time provides you with a fully tested well supported store for its use with dkron.\nConfiguration The embedded etcd instance configuration can be tunned using the standard etcd config yaml file located in config/etcd.conf.yml but several reserved parameters are autoconfigured by dkron. Refer to the official etcd documentation\n"
},
{
	"uri": "/pro/encryption/",
	"title": "Encryption",
	"tags": [],
	"description": "",
	"content": "SSL encryption is used for communicating dkron pro and the embedded store, and between storage nodes itself. Also client auth is enabled, so only dkron pro clients can talk to the embedded store. This means that no other software running on your local network will be able to talk to dkron\u0026rsquo;s etcd server.\nThis ensures that no unexpected usage of the Dkron\u0026rsquo;s store will happen, unless it is another Dkron pro instance.\nSSL encryption is enabled by default in Dkron Pro and can not be disabled, you don\u0026rsquo;t need to do nothing to use it.\n"
},
{
	"uri": "/internal/",
	"title": "Internals",
	"tags": [],
	"description": "",
	"content": " This document is a WIP, it\u0026rsquo;s intended to describe the reasons that lead to design decisions in Dkron.\nExecution results Dkron store the result of each job execution in each node.\nEvery time dkron executes a job it assigns it an execution group, generating a new uuid and send a serf query to target machines and waits for a response.\nEach target machine that will run the job, then responds with an execution object saying it started to run the job.\nThis allows dkron to know how many machines will be running the job.\nThe design takes into account the differences of how the different storage backends work.\nDue to this issue https://github.com/docker/libkv/issues/20 executions are grouped using the group id in the execution object.\nExecutions commands output When a node has finished executing a job it gathers the output of the executed command and sends it back to the a server using an RPC call. This is designed after two main reasons:\n Scallability, in case of thousands of nodes responding to job the responses are sent to dkron servers in an evenly way selecting a random Dkron server of the ones that are available at the moment and send the response. In the future, Dkron should retry sending the command result with an exponential backoff.\n Due to the limitations of Serf the queries payload can\u0026rsquo;t be bigger that 1KB, this renders impossible to send a minimal command output togheter with the execution metadata.\n  "
},
{
	"uri": "/usage/chaining/",
	"title": "Job chaining",
	"tags": [],
	"description": "",
	"content": " Job chaining You can set some jobs to run after other job is executed. To setup a job that will be executed after any other given job, just set the parent_job property when saving the new job.\nThe dependent job will be executed after the main job finished a successful execution.\nChild jobs schedule property will be ignored if it\u0026rsquo;s present.\nTake into account that parent jobs must be created before any child job.\nExample:\n{ \u0026quot;name\u0026quot;: \u0026quot;job1\u0026quot;, \u0026quot;schedule\u0026quot;: \u0026quot;@every 10s\u0026quot;, \u0026quot;executor\u0026quot;: \u0026quot;shell\u0026quot;, \u0026quot;executor_config\u0026quot;: { \u0026quot;command\u0026quot;: \u0026quot;echo \\\u0026quot;Hello from parent\\\u0026quot;\u0026quot; } } { \u0026quot;name\u0026quot;: \u0026quot;child_job\u0026quot;, \u0026quot;parent_job\u0026quot;: \u0026quot;job1\u0026quot;, \u0026quot;executor\u0026quot;: \u0026quot;shell\u0026quot;, \u0026quot;executor_config\u0026quot;: { \u0026quot;command\u0026quot;: \u0026quot;echo \\\u0026quot;Hello from child\\\u0026quot;\u0026quot; } }  "
},
{
	"uri": "/usage/retries/",
	"title": "Job retries",
	"tags": [],
	"description": "",
	"content": " Jobs can be configured to retry in case of failure.\nConfiguration { \u0026quot;name\u0026quot;: \u0026quot;job1\u0026quot;, \u0026quot;schedule\u0026quot;: \u0026quot;@every 10s\u0026quot;, \u0026quot;executor\u0026quot;: \u0026quot;shell\u0026quot;, \u0026quot;executor_config\u0026quot;: { \u0026quot;command\u0026quot;: \u0026quot;echo \\\u0026quot;Hello from parent\\\u0026quot;\u0026quot; }, \u0026quot;retries\u0026quot;: 5 }  In case of failure to run the job in one node, it will try to run the job again in that node until the retries count reaches the limit.\n"
},
{
	"uri": "/license/",
	"title": "License",
	"tags": [],
	"description": "",
	"content": "Copyright \u0026copy; Victor Castell\nDkron is an Open Source project licensed under the terms of the LGPLv3 license. Please see http://www.gnu.org/licenses/lgpl-3.0.html for license text.\n"
},
{
	"uri": "/usage/metrics/",
	"title": "Metrics",
	"tags": [],
	"description": "",
	"content": " Dkron has the ability to send metrics to Statsd for dashboards and historical reporting. It sends job processing metrics and golang, serf metrics too.\nConfiguration Add this in your yaml config file\ndog_statsd_addr: \u0026quot;localhost:8125\u0026quot;  Metrics  dkron.agent.event_received.query_execution_done dkron.agent.event_received.query_run_job dkron.memberlist.gossip dkron.memberlist.probeNode dkron.memberlist.pushPullNode dkron.memberlist.tcp.accept dkron.memberlist.tcp.connect dkron.memberlist.tcp.sent dkron.memberlist.udp.received dkron.memberlist.udp.sent dkron.rpc.call_execution_done dkron.rpc.call_get_job dkron.rpc.execution_done dkron.rpc.get_job dkron.runtime.alloc_bytes dkron.runtime.free_count dkron.runtime.gc_pause_ns dkron.runtime.heap_objects dkron.runtime.malloc_count dkron.runtime.num_goroutines dkron.runtime.sys_bytes dkron.runtime.total_gc_pause_ns dkron.runtime.total_gc_runs dkron.serf.coordinate.adjustment_ms dkron.serf.msgs.received dkron.serf.msgs.sent dkron.serf.queries dkron.serf.queries.execution_done dkron.serf.queries.run_job dkron.serf.query_acks dkron.serf.query_responses dkron.serf.queue.Event dkron.serf.queue.Intent dkron.serf.queue.Query  "
},
{
	"uri": "/usage/plugins/",
	"title": "Plugins",
	"tags": [],
	"description": "",
	"content": " Intro Plugins in Dkron allow you to add funcionality that integrates with the workflow of the job execution in Dkron. It\u0026rsquo;s a powerful system that allows you to extend and adapt Dkron to your special needs.\nThis page documents the basics of how the plugin system in Dkron works, and how to setup a basic development environment for plugin development if you\u0026rsquo;re writing a Dkron plugin.\nHow it Works Dkron execution execution processors are provided via plugins. Each plugin exposes functionality for modifying the execution. Plugins are executed as a separate process and communicate with the main Dkron binary over an RPC interface.\nThe code within the binaries must adhere to certain interfaces. The network communication and RPC is handled automatically by higher-level libraries. The exact interface to implement is documented in its respective documentation section.\nInstalling a Plugin Dkron searches for plugins at startup, to install a plugin just drop the binary in one of the following locations:\n /etc/dkron/plugins Dkron executable directory   Execution Processors   Executors   Developing plugins   "
},
{
	"uri": "/products/",
	"title": "Products",
	"tags": [],
	"description": "",
	"content": "  Dkron Pro Dkron Pro Improved security, features and reliability for your scheduled jobs Get additional fetures and commercial support from the creator of Dkron Key features Embedded storage When it comes to choose a storage you could be making a wrong decission. Easy of use comes from having a well tested and supported storage. The embedded etcd storage is tuned for use with dkron out of the box.\n  "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/usage/target-nodes-spec/",
	"title": "Target nodes spec",
	"tags": [],
	"description": "",
	"content": " Target nodes spec You can choose whether a job is run on a node or nodes by specifying tags and a count of target nodes having this tag do you want a job to run.\nExamples: Target all nodes with a tag:\n{ \u0026quot;name\u0026quot;: \u0026quot;job_name\u0026quot;, \u0026quot;command\u0026quot;: \u0026quot;/bin/true\u0026quot;, \u0026quot;schedule\u0026quot;: \u0026quot;@every 2m\u0026quot;, \u0026quot;tags\u0026quot;: { \u0026quot;role\u0026quot;: \u0026quot;web\u0026quot; } }  Target only two nodes of a group of nodes with a tag:\n{ \u0026quot;name\u0026quot;: \u0026quot;job_name\u0026quot;, \u0026quot;command\u0026quot;: \u0026quot;/bin/true\u0026quot;, \u0026quot;schedule\u0026quot;: \u0026quot;@every 2m\u0026quot;, \u0026quot;tags\u0026quot;: { \u0026quot;role\u0026quot;: \u0026quot;web:2\u0026quot; } }  Dkron will try to run the job in the amount of nodes indicated by that count having that tag.\n"
},
{
	"uri": "/usage/ecs/",
	"title": "Use with AWS ECS",
	"tags": [],
	"description": "",
	"content": " Use with Amazon ECS To use Dkron to schedule jobs that run in containers, a wrapper ECS script is needed.\nInstall the following snippet in the node that will run the call to ECS\n Prerequisites The node that will run the call to ECS will need to have installed\n AWS cli jq  Example ecs-run --cluster cron --task-definition cron-taskdef --container-name cron --region us-east-1 --command \u0026quot;rake foo\u0026quot;\n"
}]